---
layout: page
title: Projects
permalink: /Projects/
---

Graduate work in Interactive Neurorehabilitation  
========================= 

The [Mixed Reality Group for Stroke Rehabilitation](http://research.ame.asu.edu/projects/mrr) is a group of collaborators across [ASU](http://www.ame.asu.edu), [CMU](http://ideate.cmu.edu), [Emory](http://www.rehabmed.emory.edu/pt/) and [RIC](http://smpp.northwestern.edu/research/single/index.html) focused on designing interactive systems for upper extremity stroke rehabilitation. Two systems have been developed so far, one for clinical supervised training and another for training with reduced supervision, such as in the home.

<table>
<tr>
<td style="width:400px">
<div style="text-align:center" markdown="1">
<iframe src="https://player.vimeo.com/video/11640833?color=ffffff&byline=0&portrait=0" width="400" height="300"  style="border:none"></iframe> Clinical system <a name="systems"></a>
</div> 

</td>
<td style="width:400px">
<div style="text-align:center" markdown="1">
<iframe src="https://player.vimeo.com/video/121330688?color=ffffff&byline=0&portrait=0" width="400" height="300"  style="border:none"></iframe> Home System
</div> 
</td>
</tr>
</table>

*Context*

Interactive neurorehabilitation (INR) refers to the application of any interactive system to neurorehabilitation therapies (e.g. for stroke, traumatic brain injury, Parkinson’s disease). INR systems track and analyze movement of a patient practicing functional activities (e.g. reaching to grasp an object) and provide interactive feedback on performance (e.g. how directly did you reach to a target). The benefit of INR systems is that they offer accurate and detailed means for evaluating movement quality, and based on such analysis, generate augmented feedback on aspects of movement that are otherwise potentially difficult for a patient to monitor individually or in parallel (e.g. monitoring wrist location with respect to torso movement while reaching). 

While the potential for significant impact is clear, large-scale evidence supporting the best methodology for INR system design is lacking. However, information from other disciplines can help advance the design and dissemination of such systems to accelerate testing and future data-driven approaches for sensing, analysis and feedback component design.  

*Contribution*

My graduate work focused on designing feedback for INR by applying interdisciplinary concepts derived from external but related fields, such as motor learning and rehabilitation, interactive learning, media arts, and interactive computing. My [dissertation](http://repository.asu.edu/items/26862) proposes these concepts and applies them within a compositional framework (i.e. a series of suggested design constraints and approaches) for authoring visual media for INR systems for supervised training, unsupervised training, and assisted reflection. 

While the interdisciplinary concepts provided (such as multimodality, representation, adaptability, form coherence), as a collection, are specifically applied to INR and stroke rehabilitation, such an approach may also assist the development of media for other interactive learning contexts. INR presents a diverse sampling of design challenges, including a user base of various levels of ability and activity training that ranges in terms of type, supervision level, location, and timescale. Such features cut across several dimensions of experiential media systems design and can potentially inform approaches for connecting distributed experiences for general learning, behavior modification and/or awareness, creative practice, among other areas. 

A compositional framework that provides an overall approach to using the interdisciplinary concepts is proposed to help media designers (1) tailor feedback to a particular phase of interactive learning while still support an experience that both (2) fits within the overall rehabilitation training continuum and (3) allows for movement in any direction along this continuum. While the order of learning phases can vary by patient, the desired aggregate effect of using a network of experiential media systems is for the patient to gradually achieve a complex learning goal while reducing dependence on augmented feedback. 

*Contributions to the [systems shown above](#systems)*

**System for supervised training:** A visual summary of the patient’s trajectory error displayed following the AMRR system’s real-time particle feedback (designed by Loren Olson) to enhance the patient’s offline reflection on his reach performance of an individual reach and grasp. The summary was designed to translate a continuous experience (particles forming an image) into a static summary that could communicate magnitude and direction of error over time. More information on the overall system design can be found [here](http://www.jneuroengrehab.com/content/8/1/51 "Exploring the bases for a mixed reality stroke rehabilitation system, Part I: A unified approach for representing action, quantitative evaluation, and interactive feedback") and [here](http://www.jneuroengrehab.com/content/8/1/54 "Exploring the bases for a mixed reality stroke rehabilitation system, Part II: Design of Interactive Feedback for upper limb rehabilitation"), and results comparing this system to traditional rehabilitation can be found [here](http://nnr.sagepub.com/content/27/4/306.short "Adaptive Mixed Reality Rehabilitation Improves Quality of Reaching Movements More Than Traditional Reaching Therapy Following Stroke"). 


<table>
<tr>
<td style="width:546px">
<div style="text-align:left" markdown="1">
![alt text](/images/research/realtimeWithSum.jpg "Real-time feedback with summary")
</div> 
</td>
<td style="width:500px">
<div style="text-align:right" markdown="1">
![alt text](/images/research/trajExamples.jpg "Example trajectory summaries")
</div> 
</td>
</tr>
</table>

**System for unsupervised training:** A multi-level visual environment that responds to multiple aspects of the patient’s movement performance across various types of training tasks, structures of activity, and training sensitivities. The visual environment also uses various feedback design strategies to communicate movement performance, ranging from direct performance display to abstract inference of a narrative, to help facilitate self-evaluation over longer timescales of training. Multiple contexts of training are linked using an overarching distributed narrative to connect physical action to several levels of visual summary, as well as gradually facilitate the patient’s self-assessment. More information on the overall system design can be found [here](http://ptjournal.apta.org/content/95/3/449 "Interdisciplinary concepts for design and implementation of mixed reality interactive neurorehabilitation systems for stroke."). A paper on the results from a pilot study evaluating this system is forthcoming.

![alt text](/images/research/threeLevels.jpg "Three levels of feedback for home system")  

**Training Monitoring iPad app:** App designed for use by the physical therapist during weekly visits for patients engaged in unsupervised training to administer and video-record multiple standardized tasks. Once video is recorded, the therapist can segment videos into individual reaches, and tag those reaches with an overall quality label and detailed comments. The tagged videos are stored in a bank the therapist uses for composing a video story on the patient’s progress and areas for improvement. Each week the therapist can select from any of the past videos that were tagged to arrange them into an updated video story. Video stories provide a means for assisted reflection on timescales longer than those trained by the unsupervised system (e.g. by comparing progress across different weeks of training). 

<div style="text-align:center" markdown="1">
![alt text](/images/research/trainMonitorApp.jpg "Training Monitoring sample views")
</div>


<br/>


Speech therapy  
========================= 

I recently worked as a consultant for the <a href="https://chs.asu.edu/research/human-cognition/signal-analysis-representation-and-perception-sarp-laboratory">Signal Analysis, Representation, and Perception (SARP) Group</a> at <a href="http://www.asu.edu">Arizona State University</a> on developing mobile apps for speech therapy. I worked on the front end development for two apps featured [here](http://auralanalytics.com/#vita), one of which was included as a finalist in the [2014 Vodafone Wireless Innovation Competition](http://vodafone-us.com/wireless-innovation-project/past-competitions/2014/2014-finalists/).  


(*More details on projects soon*)
